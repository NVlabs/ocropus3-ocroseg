#!/usr/bin/python
import os
import re
import glob
import random as pyr
import os.path
import argparse

import torch
import scipy.ndimage as ndi
import torch.nn.functional as F
from pylab import *
from torch import nn, optim, autograd
from dlinputs import utils
from dlinputs import gopen
from dlinputs import filters
from dltrainers import helpers
from torch.autograd import Variable

from ocroseg import layers, degrade

default_degrade = "translation=0.03, rotation=1.0, scale=0.03, aniso=0.03"

rc("image", cmap="gray")
ion()

parser = argparse.ArgumentParser("train a page segmenter")
parser.add_argument("-m", "--model", default="clstm.model.py", help="load a model")
parser.add_argument("-l", "--lr", default="0,5e-3:4e4,1e-3:8e4,5e-4", help="learning rate or learning rate sequence 'n,lr:n,lr:n,:r'")
parser.add_argument("-D", "--dilate_target", default=0, type=int, help="extra dilation for target")
parser.add_argument("-M", "--maskext", default="", help="extension for mask")
parser.add_argument("-e", "--emphasis", default=10.0, type=float, help="line emphasis")
parser.add_argument("-E", "--erange", default=20, type=int, help="line emphasis range")
parser.add_argument("-o", "--output", default="temp", help="prefix for output")
parser.add_argument("-d", "--degrade", default=default_degrade, type=str, help="degradation parameters")
parser.add_argument("-S", "--scale", default=1.0, type=float, help="rescale prior to training")
parser.add_argument("-P", "--params", default="", help="additional parameters for model")
parser.add_argument("--save_every", default=1000, type=int, help="how often to save")
parser.add_argument("--loss_horizon", default=1000, type=int, help="horizon over which to calculate the loss")
args = parser.parse_args()
ARGS = {k: v for k, v in args.__dict__.items()}

def expand_image(image):
    if image is None: return None
    image = np.expand_dims(image, 0)
    image = np.expand_dims(image, 3)
    return image

source = gopen.open_source("zsub://localhost:10000/")
sample = source.next()
utils.print_sample(sample)

pipeline = filters.compose(
    filters.rename(input="png", output="lines.png", mask="mask.png"),
    filters.map(input=expand_image, output=expand_image, mask=expand_image),
    )
source = pipeline(source)
sample = source.next()
utils.print_sample(sample)

def pixels_to_batch(x):
    b, d, h, w = x.size()
    return x.permute(0, 2, 3, 1).contiguous().view(b*h*w, d)

class WeightedGrad(autograd.Function):
    def forward(self, input, weights):
        self.weights = weights
        return input
    def backward(self, grad_output):
        return grad_output * self.weights, None

def weighted_grad(x, y):
    return WeightedGrad()(x, y)

class PixelsToBatch(nn.Module):
    def forward(self, x):
        return pixels_to_batch(x)

if ":" in args.lr:
    learning_rates = [[float(y) for y in x.split(",")] for x in args.lr.split(":")]
    assert learning_rates[0][0] == 0
else:
    lr0 = float(args.lr)
    learning_rates = [[0, lr0]]

def get_lr(count):
    _, lr = learning_rates[0]
    for n, l in learning_rates:
        if count < n: break
        lr = l
    return lr

start_count = 0

execfile(args.model)
model.cuda()
print model

criterion = nn.MSELoss()
criterion.cuda()

losses = [1.0]

def zoom_like(image, shape):
    h, w = shape
    image = helpers.asnd(image)
    ih, iw = image.shape
    scale = diag([ih * 1.0/h, iw * 1.0/w])
    return ndi.affine_transform(image, scale, output_shape=(h, w), order=1)

def zoom_like_batch(batch, shape):
    b, h, w, d = batch.shape
    oh, ow = shape
    batch_result = []
    for i in range(b):
        result = []
        for j in range(d):
            result.append(zoom_like(batch[i,:,:,j], (oh, ow)))
        result = array(result).transpose(1, 2, 0)
        batch_result.append(result)
    result = array(batch_result)
    return result


def train_batch(model, image, target, mask=None, lr=1e-3):
    cuinput = torch.FloatTensor(image.transpose(0, 3, 1, 2)).cuda()
    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=0.0)
    optimizer.zero_grad()
    cuoutput = model(Variable(cuinput))
    b, d, h, w = cuoutput.size()
    if mask is not None:
        mask = zoom_like_batch(mask, (h, w))
        cumask = torch.FloatTensor(mask.transpose(0, 3, 1, 2)).cuda()
        coutput = weighted_grad(cuoutput, Variable(cumask))
    target = zoom_like_batch(target, (h, w))
    cutarget = Variable(torch.FloatTensor(target.transpose(0, 3, 1, 2)).cuda())
    loss = criterion(pixels_to_batch(cuoutput), pixels_to_batch(cutarget))
    loss.backward()
    optimizer.step()
    return loss.data.cpu().numpy()[0], helpers.asnd(cuoutput).transpose(0, 2, 3, 1)

def display_batch(image, target, output, mask=None):
    clf()
    if image is not None:
        subplot(131); imshow(image[0,:,:,0])
    if output is not None:
        subplot(132); imshow(output[0,:,:,0])
    if mask is not None:
        overlay = array([target[0,:,:,0],target[0,:,:,0],mask[0,:,:,0]],'f').transpose(1, 2, 0)
        subplot(133); imshow(overlay)
        title("mask range {}".format(amin(mask), amax(mask)))
    else:
        subplot(133); imshow(target[0,:,:,0])
    draw()
    ginput(1, 1e-3)

last_lr = -1
for i, sample in enumerate(source):
    fname = sample["__key__"]
    count = i
    image = sample["input"]
    target = sample["output"]
    mask = sample.get("mask")
    loss, output = train_batch(model, image, target, mask, 1e-1)
    print count, sample["__key__"], loss, fname, np.amin(output), np.amax(output)
    if count % 10 == 0:
        display_batch(image, target, output, mask)
