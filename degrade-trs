#!/usr/bin/python
import os
import re
import glob
import random as pyr
import os.path
import argparse

import torch
import scipy.ndimage as ndi
import torch.nn.functional as F
from pylab import *
from torch import nn, optim, autograd
from dlinputs import utils
from dlinputs import gopen
from dlinputs import filters
from dltrainers import helpers
from torch.autograd import Variable

from ocroseg import layers, degrade
from dlinputs import zcom

default_degrade = "translation=0.03, rotation=1.0, scale=0.03, aniso=0.03"

parser = argparse.ArgumentParser("train a page segmenter")
parser.add_argument("-d", "--degrade", default=default_degrade)
parser.add_argument("-f", "--fields", default="framed.png,lines.png")

parser.add_argument("--maxdelta", default="0.0,5.0")
parser.add_argument("--distort", default="20.0:100.0")

parser.add_argument("--noisesigma", default="0.5:1.5")
parser.add_argument("--noisemag", default="0.1:0.2")

parser.add_argument("--blobsper100", default="0.0,0.3")
parser.add_argument("--blobsize", default="1.0:20.0")
parser.add_argument("--rotation_limit", type=float, default=0.1)

parser.add_argument("--limit", type=int, default=1000000000)

parser.add_argument("input")
parser.add_argument("output")
args = parser.parse_args()

ifield, ofield = args.fields.split(",")


assert not os.path.exists(args.output)

degradation = eval("dict(%s)" % default_degrade)

def R(r):
    if "," in r:
        lo, hi = [float(x) for x in r.split(",")]
        return np.random.uniform(lo, hi)
    elif ":" in r:
        lo, hi = [float(x) for x in r.split(":")]
        return np.exp(np.random.uniform(np.log(lo), np.log(hi)))
    else:
        return float(r)


def degrade_sample(sample):
    input = sample["input"]
    output = sample["output"]
    h, w = input.shape
    #print "*blobs"
    nblobs = int(R(args.blobsper100) * h * w / (100.0 * 100.0))
    input = np.maximum(input, degrade.random_blobs((h, w), nblobs, R(args.blobsize)))
    #print "*gauss"
    input = degrade.gauss_degrade(input, R(args.noisesigma), R(args.noisemag))
    #print "*distort"
    input, output = degrade.random_distort([input, output],
                                           maxdelta=R(args.maxdelta),
                                           sigma=R(args.distort))
    #print "*trs"
    f, params = degrade.random_trs(rotation=args.rotation_limit)
    input, output = f(input), f(output)
    input = clip(input, 0, 1)
    output = clip(output, 0, 1)
    #print "*done"
    return dict(input=input, output=output)

pipeline = filters.compose(
    filters.ren({"input": ifield, "output": ofield}),
    filters.transform(degrade_sample),
    filters.ren({ifield: "input", ofield: "output"}),
)

source = gopen.sharditerator_once(args.input)
source = pipeline(source)
sink = gopen.open_sink(args.output)
for i, sample in enumerate(source):
    if i>=args.limit: break
    if i%1==0: print i, sample.get("__key__")
    if i==0: utils.print_sample(sample)
    sink.write(sample)
